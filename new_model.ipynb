{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 19 January "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "toilets = pd.read_csv(\"toilets.csv\")\n",
    "waste_management = pd.read_csv(\"waste_management.csv\")\n",
    "water_sources = pd.read_csv(\"water_sources.csv\")\n",
    "\n",
    "# Combine train and test datasets for consistent preprocessing\n",
    "hospital_data = pd.concat([train, test])\n",
    "\n",
    "# Drop unnecessary columns from supplementary datasets\n",
    "for df in [toilets, waste_management, water_sources]:\n",
    "    df.drop(columns=['Year', 'Month'], inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "def rename_columns(df, prefix):\n",
    "    for col in df.columns:\n",
    "        if col not in ['Month_Year_lat_lon', 'lat_lon']:\n",
    "            df.rename(columns={col: f\"{prefix}_{col}\"}, inplace=True)\n",
    "\n",
    "rename_columns(toilets, \"toilet\")\n",
    "rename_columns(waste_management, \"waste\")\n",
    "rename_columns(water_sources, \"water\")\n",
    "\n",
    "# Ensure unique identifier columns exist in all supplementary datasets\n",
    "\n",
    "\n",
    "\n",
    "# Fill missing values in the 'Total' column\n",
    "hospital_data['Total'].fillna(0, inplace=True)\n",
    "\n",
    "# Drop rows with missing latitude and longitude in water sources\n",
    "water_sources.dropna(subset=['water_Transformed_Latitude'], inplace=True)\n",
    "\n",
    "# Function to find nearest locations\n",
    "def find_nearest(hospital_data, location_df, lat_col, lon_col, id_col):\n",
    "    # Create a cKDTree for efficient nearest neighbour search\n",
    "    tree = cKDTree(location_df[[lat_col, lon_col]].values)\n",
    "    nearest = {}\n",
    "    # Loop through each hospital and find the nearest site in location_df\n",
    "    for _, row in hospital_data.iterrows():\n",
    "        _, idx = tree.query([row['Transformed_Latitude'], row['Transformed_Longitude']])\n",
    "        nearest[row['ID']] = location_df.iloc[idx][id_col]\n",
    "    return nearest\n",
    "\n",
    "for df, prefix in [(toilets, 'toilet'), (waste_management, 'waste'), (water_sources, 'water')]:\n",
    "   df[f\"{prefix}_Month_Year_lat_lon\"] = (\n",
    "      df[f\"{prefix}_Month_Year\"] + '_' +\n",
    "      df[f\"{prefix}_Transformed_Latitude\"].astype(str) + '_' +\n",
    "      df[f\"{prefix}_Transformed_Longitude\"].astype(str)\n",
    "    )\n",
    "\n",
    "\n",
    "# Merge datasets with nearest locations\n",
    "merged_data = hospital_data.copy()\n",
    "datasets = [\n",
    "    (toilets, 'toilet', 'toilet_Month_Year_lat_lon'),\n",
    "    (waste_management, 'waste', 'waste_Month_Year_lat_lon'),\n",
    "    (water_sources, 'water', 'water_Month_Year_lat_lon'),\n",
    "]\n",
    "\n",
    "for df, prefix, id_col in datasets:\n",
    "    nearest = find_nearest(merged_data, df, f\"{prefix}_Transformed_Latitude\", f\"{prefix}_Transformed_Longitude\", id_col)\n",
    "    nearest_df = pd.DataFrame(list(nearest.items()), columns=['ID', id_col])\n",
    "    merged_data = merged_data.merge(nearest_df, on=\"ID\").merge(df, on=id_col)\n",
    "\n",
    "# Split merged data into train and test sets\n",
    "train_df = merged_data[merged_data['Year'] < 2023]\n",
    "test_df = merged_data[merged_data['Year'] == 2023]\n",
    "\n",
    "# Specify the target column\n",
    "target_column = 'Total'\n",
    "\n",
    "# Feature and target split\n",
    "X = train_df.drop(columns=[target_column, 'ID', 'Location'], errors='ignore')\n",
    "y = train_df[target_column]\n",
    "\n",
    "# Handle categorical features\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for XGBoost\n",
    "xgb = XGBRegressor(random_state=42, verbosity=0)\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "# Create a hybrid model using Voting Regressor\n",
    "hybrid_model = VotingRegressor([('RandomForest', best_rf), ('XGBoost', best_xgb)])\n",
    "hybrid_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = hybrid_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Prepare test data\n",
    "X_test_final = test_df.drop(columns=['Total', 'ID', 'Location'], errors='ignore')\n",
    "\n",
    "# Handle categorical features in test data\n",
    "for col in categorical_cols:\n",
    "    if col in X_test_final.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_test_final[col] = le.fit_transform(X_test_final[col])\n",
    "\n",
    "# Align test dataset with training features\n",
    "for col in X.columns:\n",
    "    if col not in X_test_final.columns:\n",
    "        X_test_final[col] = 0  # Add missing feature with default value (e.g., zero)\n",
    "\n",
    "# Ensure columns are in the same order as training\n",
    "X_test_final = X_test_final[X.columns]\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = hybrid_model.predict(X_test_final)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "test_predictions = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'Predictions': predictions\n",
    "})\n",
    "\n",
    "test_predictions.to_csv(\"test_predictions.csv\", index=False)\n",
    "print(\"Predictions saved to 'test_predictions.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
